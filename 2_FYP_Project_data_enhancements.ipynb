{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfc16d2",
   "metadata": {},
   "source": [
    "## Data enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39a230bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155a0e9",
   "metadata": {},
   "source": [
    "### Pre-processing images in data\n",
    "** note that only training data will undergo enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea91a27",
   "metadata": {},
   "source": [
    "#### Image enhancement\n",
    "The process of improving the appearance of images to highlight specific features, reduce noise or improve the quality of the image, this helps it to be more suitable for analysis.\n",
    "\n",
    "Alpha focuses on the contrast of image\n",
    "- alpha greater than 1: images brighter, enhanced contrast\n",
    "- alpha less than 1: images darker, reduced contrast\n",
    "\n",
    "Beta focuses on brightness of image\n",
    "- beta positive: makes images brighter\n",
    "- beta negative: makes images darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "becbd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/csv/train_data.csv\")\n",
    "test_data = pd.read_csv(\"datasets/csv/test_data.csv\")\n",
    "\n",
    "## PREPROCESSING IMAGES WITH ENHANCEMENT\n",
    "def preprocess_image(img_path, enhance):\n",
    "    # reading images\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if enhance == True:\n",
    "        # enhancing image\n",
    "        img = cv2.convertScaleAbs(img, alpha = 1.5, beta = -20)\n",
    "    # target_size of 224, 224 commonly used for image classification\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # normalising pixel values\n",
    "    img_array = img.astype(np.float32) / 255\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4661e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using preprocessed images as train data\n",
    "train_images = np.array([preprocess_image(image_path, True) for image_path in train_data[\"image_path\"]])\n",
    "# using \"pathology\" column as train labels\n",
    "train_labels = np.array(train_data[\"pathology\"])\n",
    "\n",
    "# change \"BENIGN_WITHOUT_CALLBACK\" to \"BENIGN\"\n",
    "train_labels[train_labels == \"BENIGN_WITHOUT_CALLBACK\"] = \"BENIGN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac431677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using preprocessed images as test data\n",
    "test_images = np.array([preprocess_image(image_path, False) for image_path in test_data[\"image_path\"]])\n",
    "# using \"pathology\" column as test labels\n",
    "test_labels = np.array(test_data[\"pathology\"])\n",
    "\n",
    "# change \"BENIGN_WITHOUT_CALLBACK\" to \"BENIGN\"\n",
    "test_labels[test_labels == \"BENIGN_WITHOUT_CALLBACK\"] = \"BENIGN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e925d57",
   "metadata": {},
   "source": [
    "#### Image augmentation\n",
    "```ImageDataGenerator``` provides real-time data augmentation. Generates augmented images on-the-fly. For this project it is fixed so just need horizontal and vertical flips. To ensure that at least basic method of flipping works, a Numpy version will be implemented followed by the ```ImageDataGenerator``` version, this also tests which version of augmentation is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c318cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERSION 1 OF IMAGE AUGMENTATION - using numpy\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# augmenting images and storing in lists\n",
    "for i, img_path in enumerate(train_data[\"image_path\"]):\n",
    "    original_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    enhanced_image = preprocess_image(img_path, True)\n",
    "    \n",
    "    # adding original image and label\n",
    "    augmented_images.append(enhanced_image)\n",
    "    augmented_labels.append(train_labels[i])\n",
    "    \n",
    "    # making all combinations of flips\n",
    "    for horizontal_flip in [True, False]:\n",
    "        for vertical_flip in [True, False]:\n",
    "            # applying flips\n",
    "            augmented_image = enhanced_image\n",
    "            if horizontal_flip:\n",
    "                augmented_image = np.fliplr(augmented_image)\n",
    "            if vertical_flip:\n",
    "                augmented_image = np.flipud(augmented_image)\n",
    "                \n",
    "            # adding augmented image and label\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(train_labels[i])\n",
    "        \n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_train_labels = label_encoder.fit_transform(train_labels)\n",
    "encoded_aug_train_labels = label_encoder.fit_transform(augmented_labels)\n",
    "encoded_test_labels = label_encoder.fit_transform(test_labels)\n",
    "# one-hot encode labels\n",
    "one_hot_train_labels = tf.keras.utils.to_categorical(encoded_train_labels)\n",
    "one_hot_aug_train_labels = tf.keras.utils.to_categorical(encoded_aug_train_labels)\n",
    "one_hot_test_labels = tf.keras.utils.to_categorical(encoded_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7228841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERSION 2 OF IMAGE AUGMENTATION - using TensorFlow\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\"\n",
    ")\n",
    "\n",
    "# version 2 of augmenting images\n",
    "augmented_generator = datagen.flow(train_images[:, :, :, np.newaxis], one_hot_train_labels, batch_size = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5ffaa",
   "metadata": {},
   "source": [
    "## Creating of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = Sequential()\n",
    "# creating stack of Conv2D and MaxPooling2D\n",
    "base_model1.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "base_model1.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# unrolling output to 1D\n",
    "base_model1.add(Flatten())\n",
    "base_model1.add(Dense(128, activation = \"relu\"))\n",
    "# output layer with softmax\n",
    "base_model1.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "base_model2 = Sequential()\n",
    "# creating stack of Conv2D and MaxPooling2D\n",
    "base_model2.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "base_model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# unrolling output to 1D\n",
    "base_model2.add(Flatten())\n",
    "base_model2.add(Dense(128, activation = \"relu\"))\n",
    "# output layer with softmax\n",
    "base_model2.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce4ade",
   "metadata": {},
   "source": [
    "It was noted that whilst the adam optimizer had the highest accuracy, the nadam optimizer has a higher validation accuracy, which would suggest a change in choice to the preliminary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12218cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model, improving accuracy\n",
    "base_model1.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "# train model, validating on test set\n",
    "history = base_model1.fit(augmented_images, one_hot_aug_train_labels, epochs = 10, validation_data = (test_images, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model, improving accuracy\n",
    "base_model2.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "# train model, validating on test set\n",
    "history = base_model2.fit(augmented_generator, epochs = 10, validation_data = (test_images[:, :, :, np.newaxis], one_hot_test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
