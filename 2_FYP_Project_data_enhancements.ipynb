{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfc16d2",
   "metadata": {},
   "source": [
    "## Data enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a230bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155a0e9",
   "metadata": {},
   "source": [
    "### Pre-processing images in data\n",
    "** note that only training data will undergo enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea91a27",
   "metadata": {},
   "source": [
    "#### Image enhancement\n",
    "The process of improving the appearance of images to highlight specific features, reduce noise or improve the quality of the image, this helps it to be more suitable for analysis.\n",
    "\n",
    "Alpha focuses on the contrast of image\n",
    "- alpha greater than 1: images brighter, enhanced contrast\n",
    "- alpha less than 1: images darker, reduced contrast\n",
    "\n",
    "Beta focuses on brightness of image\n",
    "- beta positive: makes images brighter\n",
    "- beta negative: makes images darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becbd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"datasets/csv/train_data.csv\")\n",
    "test_data = pd.read_csv(\"datasets/csv/test_data.csv\")\n",
    "\n",
    "## PREPROCESSING IMAGES WITH ENHANCEMENT\n",
    "def preprocess_image(img_path, enhance):\n",
    "    # reading images\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if enhance == True:\n",
    "        # enhancing image\n",
    "        img = cv2.convertScaleAbs(img, alpha = 1.5, beta = -20)\n",
    "    # target_size of 224, 224 commonly used for image classification\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # normalising pixel values\n",
    "    img_array = img.astype(np.float32) / 255\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4661e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using preprocessed images as train data\n",
    "train_images = np.array([preprocess_image(image_path, True) for image_path in train_data[\"image_path\"]])\n",
    "# using \"pathology\" column as train labels\n",
    "train_labels = np.array(train_data[\"pathology\"])\n",
    "\n",
    "# change \"BENIGN_WITHOUT_CALLBACK\" to \"BENIGN\"\n",
    "train_labels[train_labels == \"BENIGN_WITHOUT_CALLBACK\"] = \"BENIGN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac431677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using preprocessed images as test data\n",
    "test_images = np.array([preprocess_image(image_path, False) for image_path in test_data[\"image_path\"]])\n",
    "# using \"pathology\" column as test labels\n",
    "test_labels = np.array(test_data[\"pathology\"])\n",
    "\n",
    "# change \"BENIGN_WITHOUT_CALLBACK\" to \"BENIGN\"\n",
    "test_labels[test_labels == \"BENIGN_WITHOUT_CALLBACK\"] = \"BENIGN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e925d57",
   "metadata": {},
   "source": [
    "#### Image augmentation\n",
    "The augmented image stores the following:\n",
    "- original image without enhancement\n",
    "- enhanced image with enhancement\n",
    "- all combinations of augmented flips (with enhancement)\n",
    "- all combinations of augmented flips (without enhancement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c318cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18816\n",
      "18816\n"
     ]
    }
   ],
   "source": [
    "## IMAGE AUGMENTATION - using numpy\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "# augmenting images and storing in lists\n",
    "for i, img_path in enumerate(train_data[\"image_path\"]):\n",
    "    original_image = preprocess_image(img_path, False)\n",
    "    enhanced_image = preprocess_image(img_path, True)\n",
    "    \n",
    "    # making all combinations of flips\n",
    "    for horizontal_flip in [True, False]:\n",
    "        for vertical_flip in [True, False]:\n",
    "            # applying flips on original image\n",
    "            augmented_image = original_image\n",
    "            if horizontal_flip:\n",
    "                augmented_image = np.fliplr(augmented_image)\n",
    "            if vertical_flip:\n",
    "                augmented_image = np.flipud(augmented_image)\n",
    "                \n",
    "            # adding augmented image and label\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(train_labels[i])\n",
    "            \n",
    "            # applying flips on enhanced image\n",
    "            augmented_image = enhanced_image\n",
    "            if horizontal_flip:\n",
    "                augmented_image = np.fliplr(augmented_image)\n",
    "            if vertical_flip:\n",
    "                augmented_image = np.flipud(augmented_image)\n",
    "                \n",
    "            # adding augmented image and label\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(train_labels[i])\n",
    "        \n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(len(train_labels) * 8)\n",
    "print(len(augmented_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1605c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_train_labels = label_encoder.fit_transform(train_labels)\n",
    "encoded_aug_train_labels = label_encoder.fit_transform(augmented_labels)\n",
    "encoded_test_labels = label_encoder.fit_transform(test_labels)\n",
    "# one-hot encode labels\n",
    "one_hot_train_labels = tf.keras.utils.to_categorical(encoded_train_labels)\n",
    "one_hot_aug_train_labels = tf.keras.utils.to_categorical(encoded_aug_train_labels)\n",
    "one_hot_test_labels = tf.keras.utils.to_categorical(encoded_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7228841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## VERSION 2 OF IMAGE AUGMENTATION - using TensorFlow\n",
    "## datagen = ImageDataGenerator(\n",
    "##     horizontal_flip = True,\n",
    "##     vertical_flip = True,\n",
    "##     fill_mode = \"nearest\"\n",
    "## )\n",
    "## \n",
    "## augmented_generator = datagen.flow(train_images[:, :, :, np.newaxis], one_hot_train_labels, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5ffaa",
   "metadata": {},
   "source": [
    "## Creating of models\n",
    "- **Conv2D** performs convolutional operations on the input image data. It applies a set of filters to the input images to extract features.\n",
    "- **MaxPooling2D** is a down-sampling operation that reduces the spatial dimensions, used after Conv2D layers to retain the most important information.\n",
    "- **Flatten** is used to convert the multi-dimensional output of the previous laters into 1D.\n",
    "- **Dense** represents a fully connected layer, where each neuron or node is connected to every neuron in the previous layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1cb64",
   "metadata": {},
   "source": [
    "### Base model\n",
    "Ensures that the data can be trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bebd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "# creating stack of Conv2D and MaxPooling2D\n",
    "base_model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "base_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# unrolling output to 1D\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(128, activation = \"relu\"))\n",
    "# output layer with softmax\n",
    "base_model.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce4ade",
   "metadata": {},
   "source": [
    "It was noted that whilst the adam optimizer had the highest accuracy, the nadam optimizer has a higher validation accuracy, which would suggest a change in choice to the preliminary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12218cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "588/588 [==============================] - 445s 752ms/step - loss: 0.7211 - accuracy: 0.6105 - val_loss: 0.6284 - val_accuracy: 0.6480\n",
      "Epoch 2/10\n",
      "588/588 [==============================] - 440s 748ms/step - loss: 0.5543 - accuracy: 0.7021 - val_loss: 0.6315 - val_accuracy: 0.6480\n",
      "Epoch 3/10\n",
      "588/588 [==============================] - 442s 751ms/step - loss: 0.3836 - accuracy: 0.8254 - val_loss: 0.7155 - val_accuracy: 0.6514\n",
      "Epoch 4/10\n",
      "588/588 [==============================] - 444s 755ms/step - loss: 0.2150 - accuracy: 0.9210 - val_loss: 0.9113 - val_accuracy: 0.6395\n",
      "Epoch 5/10\n",
      "588/588 [==============================] - 444s 755ms/step - loss: 0.1098 - accuracy: 0.9709 - val_loss: 1.0695 - val_accuracy: 0.6310\n",
      "Epoch 6/10\n",
      "588/588 [==============================] - 443s 754ms/step - loss: 0.0726 - accuracy: 0.9862 - val_loss: 1.2130 - val_accuracy: 0.6395\n",
      "Epoch 7/10\n",
      "588/588 [==============================] - 442s 752ms/step - loss: 0.0620 - accuracy: 0.9891 - val_loss: 1.2193 - val_accuracy: 0.6463\n",
      "Epoch 8/10\n",
      "588/588 [==============================] - 439s 746ms/step - loss: 0.0575 - accuracy: 0.9901 - val_loss: 1.3313 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "588/588 [==============================] - 445s 756ms/step - loss: 0.0508 - accuracy: 0.9906 - val_loss: 1.3496 - val_accuracy: 0.6293\n",
      "Epoch 10/10\n",
      "588/588 [==============================] - 441s 751ms/step - loss: 0.0521 - accuracy: 0.9912 - val_loss: 1.2668 - val_accuracy: 0.6276\n"
     ]
    }
   ],
   "source": [
    "# compile model, improving accuracy\n",
    "base_model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "# train model, validating on test set\n",
    "history = base_model.fit(augmented_images, one_hot_aug_train_labels, epochs = 10, validation_data = (test_images, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c9383",
   "metadata": {},
   "source": [
    "### Improving with additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb01203",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer_model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "twoLayer_model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "twoLayer_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# second convolutional layer\n",
    "twoLayer_model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "twoLayer_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# unrolling output to 1D\n",
    "twoLayer_model.add(Flatten())\n",
    "twoLayer_model.add(Dense(128, activation = \"relu\"))\n",
    "# using dropout for regularisation (reduces overfitting)\n",
    "twoLayer_model.add(Dropout(0.5))\n",
    "# output layer with softmax\n",
    "twoLayer_model.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8581077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compile model, improving accuracy\n",
    "twoLayer_model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "# train model, validating on test set\n",
    "history = twoLayer_model.fit(augmented_images, one_hot_aug_train_labels, epochs = 10, validation_data = (test_images, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeLayer_model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "threeLayer_model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "threeLayer_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# second convolutional layer\n",
    "threeLayer_model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "threeLayer_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# third convolutional layer\n",
    "threeLayer_model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "threeLayer_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# unrolling output to 1D\n",
    "threeLayer_model.add(Flatten())\n",
    "threeLayer_model.add(Dense(128, activation = \"relu\"))\n",
    "# using dropout for regularisation (reduces overfitting)\n",
    "threeLayer_model.add(Dropout(0.5))\n",
    "# output layer with softmax\n",
    "threeLayer_model.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3c139",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compile model, improving accuracy\n",
    "threeLayer_model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "# train model, validating on test set\n",
    "history = threeLayer_model.fit(augmented_images, one_hot_aug_train_labels, epochs = 10, validation_data = (test_images, one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c922f8a",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "To conduct hyperparameter tuning, it is beneficial to wrap the model in a function. This makes it scikit-learn compatable as there will be methods like Grid Search and Randomised Search to help optimise the performance of the neural network.\n",
    "\n",
    "As more runs will be done, adding verbose = 2 makes the information printed a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8d604a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model as a function\n",
    "def create_3Layer_model(dropout_rate = 0.5, **kwargs):\n",
    "    model = Sequential()\n",
    "\n",
    "    # first convolutional layer\n",
    "    model.add(Conv2D(32, (3, 3), activation = \"relu\", input_shape = (224, 224, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # second convolutional layer\n",
    "    model.add(Conv2D(64, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # third convolutional layer\n",
    "    model.add(Conv2D(128, (3, 3), activation = \"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # unrolling output to 1D\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    # using dropout for regularisation (reduces overfitting)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # output layer with softmax\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    \n",
    "    # compile model, improving accuracy\n",
    "    model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    # train model, validating on test set\n",
    "    history = model.fit(augmented_images, one_hot_aug_train_labels, epochs = 10, validation_data = (test_images, one_hot_test_labels))\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b622821",
   "metadata": {},
   "source": [
    "#### Conducting Grid Search\n",
    "[modify]\n",
    "Grid search involves defining a grid of hyperparameter values and training the model for each combination. It's a brute-force approach that explores a predefined set of hyperparameter values.\n",
    "\n",
    "```\n",
    "# Create the KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'nadam', 'rmsprop'],\n",
    "    'dropout_rate': [0.2, 0.4, 0.6],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(augmented_images, one_hot_aug_train_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6484ae",
   "metadata": {},
   "source": [
    "# help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65f77160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter dropout_rate for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(dropout_rate=0.2)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# performing grid search - 5 fold grid search\u001b[39;00m\n\u001b[0;32m      9\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m model_for_grid, param_grid \u001b[38;5;241m=\u001b[39m parameter)\n\u001b[1;32m---> 10\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_aug_train_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    718\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 720\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcloned_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    724\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{param: value})\n\u001b[0;32m   1162\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;66;03m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;66;03m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[1;32m-> 1165\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1166\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1167\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1168\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1169\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1170\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheck the list of available parameters with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1171\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `estimator.get_params().keys()`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1172\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter dropout_rate for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(dropout_rate=0.2)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "# creating the Keras classifier\n",
    "model_for_grid = KerasClassifier(build_fn = create_3Layer_model, epochs = 10, batch_size = 32, verbose = 2)\n",
    "# defining hyperparameters\n",
    "parameter = {\n",
    "    'dropout_rate': [0.2, 0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "# performing grid search - 5 fold grid search\n",
    "grid = GridSearchCV(estimator = model_for_grid, param_grid = parameter)\n",
    "grid_results = grid.fit(augmented_images, one_hot_aug_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366a199",
   "metadata": {},
   "source": [
    "#### Conducting Random Search\n",
    "[modify] Random search randomly samples hyperparameter values from predefined ranges. It is more efficient than grid search and can be effective in high-dimensional spaces.\n",
    "\n",
    "```\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create the KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameters and their distributions to sample from\n",
    "param_dist = {\n",
    "    'optimizer': ['adam', 'nadam', 'rmsprop'],\n",
    "    'dropout_rate': uniform(0.2, 0.6),\n",
    "}\n",
    "\n",
    "# Perform random search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_result = random_search.fit(augmented_images, one_hot_aug_train_labels)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
